#importing opencvlibrary for basic image processing function
import cv2
#numpy for array related functions
import numpy as np
#dlib for deep learning modules and face landmark detection
import dlib 
#face_utils foe basic operations of conversion
from imutils import face_utils
import time
from playsound import playsound
from face_detector import get_face_detector,find_faces
from face_landmarks import get_landmark_model, detect_marks
#initialising the cam and taking the instance
cap = cv2.VideoCapture(0)

#initialising the face and landmark detector
detector = dlib.get_frontal_face_detector()
predictor =dlib.shape_predctor("shape_predictor_68_face_landmarks.dat")

#status marking for the current state
sleep = 0
drowsy = 0
active = 0
status = ""
color = (0,0,0)

def compute(ptA,ptB):
  dist = np.linalg.norm(ptA-ptB)
  return dist


def blinked(a,b,c,d,e,f):
  up = compute(b,d)+ compute(c,e)
  down=compute(a,f)
  ratio=up/(2.0*down)

  #is driver blinking?
  # NOTE: change the values according to our system later, trial and error
  if ratio>0.25:  #opened eye
    return 2
  elif (ratio > 0.21 and ratio<=0.25): #droopy eye
    return 1
  else:  #closed eye
    return 0

while True: # 2 or 1
    _, frame = cap.read() # returns ret variable and camera frame
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # changes BGR to RGB (openCV read in BGR)

    faces = detector(gray)
    #detected face in faces array
    for face in faces:  #frontal face detector rectangle that is formed
      x1 = face.left()
      y1 = face.top()
      x2 = face.right()
      y2 = face.bottom()

      face_frame = frame.copy()
      cv2.rectangle(face_frame, (x1,y1), (x2,y2), (0,255,0), 2)

      landmarks = predictor(gray, face) #(frame, region of interest)
      landmarks = face_utils.shape_to_np(landmarks)  #shaping dlib result in numpy array

      #eye landmarks (redcued by 1 bc array index)

      left_blink = blinked(landmarks[36],landmarks[37], 
        landmarks[38], landmarks[41], landmarks[40], landmarks[39])
      right_blink = blinked(landmarks[42],landmarks[43], 
        landmarks[44], landmarks[47], landmarks[46], landmarks[45])

      #state of the person is judged below

      
      if(left_blink==0 or right_blink==0):
        sleep+=1
        drowsy=0
        active=0
        if(sleep>6):
        	status="SLEEPING !!!"
        	color = (255,0,0)

      elif(left_blink==1 or right_blink==1):
        sleep=0
        active=0
        drowsy+=1
        if(drowsy>6):
        	status="Drowsy !"
        	color = (0,0,255)

      else:
        drowsy=0
        sleep=0
        active+=1
        if(active>6):
        	status="Active :)"
        	color = (0,255,0)
          
      cv2.putText(frame, status, (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color,3)

    for n in range(0, 68):
        (x,y) = landmarks[n]
        cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)

  cv2.imshow("Frame", frame)
  cv2.imshow("Result of detector", face_frame)
  key = cv2.waitKey(1)
  if key == 27:
      break
      
      
      
      
    
  
  
  





















#ANUSHKA'S DOMAIN
#DO NOT ENTER okay

def eye_on_mask(mask,side,shape):
  """
  Create ROI on mask of the size of eyes 
  Find extreme points of each eye

  Parameters:
  mask:np.uint8
    Blank mask to draw eyes on
  side:list of int
    the facial landmark numbers of eyes
  shape:Array of uint32
    Facial landmarks

  Returns
  mask: np.uint8
    Mask with region of interest drawn
  [l,t,r,b]:list
    left,top,right and bottom most point of ROI 
  """
  points=[shape[i] for i in side]
  points=np.array(points, dtype=np.int32)
  mask=cv2.fillConvexPoly(mask,points,255)
  l=points[0][0]
  t=(points[1][1]+points[2][1])//2
  r=points[3][0]
  b=(points[4][1]+points[5][1])//2
  return mask, [l,t,r,b]

def find_eyeball_position(end_points,cx,cy):
  """
  Find and return position of eyeball
  """
  x_ratio=(end_points[0]-cx)/(cx-end_points[2])
  y_ratio=(cy-end_points[1])/(end_points[3]-cy)
  if x_ratio>3 or x_ratio<0.33 or y_ratio<0.33:
    print("X_Ratio:"+x_ratio)
    print("Y_Ratio:"+y_ratio)
    return 1
  else:
    return 0

def contouring(thresh,mid,img,end_points,right=False):
  """
  Find the largest contour on an image divided by a midpoint and subsequently the eye position

  Parameters
  thresh: Array of uint8
    Thresholded image of one side containing the eyeball
  mid: int
    The mid point between the eyes
  img: Array of uint8
    Original Image
  end_points:list
    List containing the extreme points of eye
  right: boolean,optional
    whether calculating for right eye or left. The default is false

  Returns
  pos: int
    the position where eyeball is:
      0 for normal
      1 for left
      2 for right
      3 for up
      4 for down
  
  """
cnts, _= cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)
try:
  cnt=max(cnts,key=cv2.contourArea)
  M=cv2.moments(cnt)
  cx=int(M['m10']/M['m00'])
  cy=int(M['m01']/M['m00'])
  if right:
    cx+=mid
  cv2.circle(img,(cx,cy),4,(0,0,255),2)
  pos=find_eyeball_position(end_points,cx,cy)
  return pos
except:
  pass

def process_thresh(thresh):
  """
  Preprocessing the threshold image

  Parameters
  thresh:Array of uint8
    Thresholded image to preprocess

  Returns
  thresh: Array of uint8
    Processed thresholded image

  """
  

